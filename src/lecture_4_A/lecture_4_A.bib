\begin{thebibliography}{4}

@article{littman2015reinforcement,
  title={Reinforcement learning improves behaviour from evaluative feedback},
  author={Littman, Michael L},
  journal={Nature},
  volume={521},
  number={7553},
  pages={445--451},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{LITTLESTONE1994212,
title = {The Weighted Majority Algorithm},
journal = {Information and Computation},
volume = {108},
number = {2},
pages = {212-261},
year = {1994},
issn = {0890-5401},
doi = {https://doi.org/10.1006/inco.1994.1009},
url = {https://www.sciencedirect.com/science/article/pii/S0890540184710091},
author = {N. Littlestone and M.K. Warmuth},
abstract = {We study the construction of prediction algorithms in a situation in which a learner faces a sequence of trials, with a prediction to be made in each, and the goal of the learner is to make few mistakes. We are interested in the case where the learner has reason to believe that one of some pool of known algorithms will perform well, but the learner does not know which one. A simple and effective method, based on weighted voting, is introduced for constructing a compound algorithm in such a circumstance. We call this method the Weighted Majority Algorithm. We show that this algorithm is robust in the presence of errors in the data. We discuss various versions of the Weighted Majority Algorithm and prove mistake bounds for them that are closely related to the mistake bounds of the best algorithms of the pool. For example, given a sequence of trials, if there is an algorithm in the pool A that makes at most m mistakes then the Weighted Majority Algorithm will make at most c(log |A| + m) mistakes on that sequence, where c is fixed constant.}
}
\end{thebibliography}